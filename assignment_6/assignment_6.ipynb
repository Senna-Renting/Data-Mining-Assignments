{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "STUDENT_NUMBER = \"\"\n",
    "COLLABORATOR_NAME = \"\"\n",
    "COLLABORATOR_STUDENT_NUMBER = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Important:** When handing in your homework:\n",
    "+ Hand in the notebook (and nothing else) **named as follows**: StudentName1_snumber_StudentName2_snumber.ipynb\n",
    "+ Provide clear and complete answers to the questions below under a separate header (not hidden somewhere in your source code), and make sure to explain your answers / motivate your choices. Add Markdown cells where necessary.\n",
    "+ Source code, output graphs, derivations, etc., should be included in the notebook.\n",
    "+ Hand-in: upload to Brightspace.\n",
    "+ Include name, student number, assignment (especially in filenames)!\n",
    "+ When working in pairs only one of you should upload the assignment, and report the name of your partner in your filename.\n",
    "+ Use the Brightspace discussion board or email the student assistants for questions on how to complete the exercises.\n",
    "+ If you find mistakes/have suggestions/would like to complain about the assigment material itself, please email me [Roel] at `Roel.Bouman@ru.nl`\n",
    "+ Do not remove any cells in the notebook, else this might break the auto-grading system. **An invalid notebook will mean a severe reduction in your grade!**\n",
    "+ Many online collaboration platforms remove metadata from notebooks, which breaks the auto-grading system. Again, **An invalid notebook will mean a severe reduction in your grade!**. Should you wish to use these platforms, copy the answers from the online notebook to one running on your own machine with Anaconda, and then execute all cells.\n",
    "+ Only type your answers in those places where they are asked.\n",
    "+ Remove any \"raise NotImplementedError()\" statements in the cells you answered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4595b5965904d027a5ff2190d916a8e",
     "grade": false,
     "grade_id": "cell-4543b21b34b8c4a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 6: Nearest Neighbour and Artificial Neural Networks\n",
    "\n",
    "## Objective of this assignment\n",
    "The objective of this exercise is to understand how k-nearest neighbor and neural networks can be used to solve classification problems.\n",
    "\n",
    "\n",
    "## Advised Reading and Exercise Material\n",
    "**The following reading material is recommended:**\n",
    "\n",
    "- Pang-Ning Tan, Michael Steinbach, and Vipin Kumar, *Introduction to Data Mining*, section 5.2-5.4.\n",
    "\n",
    "\n",
    "## Additional Tools\n",
    "This exercise is based upon material kindly provided by the Cognitive System Section, DTU Compute, http://cogsys.compute.dtu.dk. Any sale or commercial distribution is strictly forbidden.\n",
    "\n",
    "\n",
    "##  6.1 K-nearest neighbor classification\n",
    "In this exercise we will use the k-nearest neighbors (KNN) method for classification.\n",
    "First, we will consider the four synthetic data sets synth1, synth2, synth3 and\n",
    "synth4 we used in earlier assignments.\n",
    "\n",
    "#### 6.1.1 (2 points)\n",
    "For each of the four synthetic data sets, do the following.:\n",
    "\n",
    "* Load the training part of the dataset `X_train` and `y_train` as well as `X_test` and `y_test`.\n",
    "\n",
    "* Fit a  k-nearest neighbor classifier model (`KNeighborsClassifier` from `sklearn.neighbors` (http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) on the train data. \n",
    "  * Choose a suitable distance measure (you should consider the distance measures `euclidean`,`cityblock`, `cosine`, and `seuclidean`).\n",
    "    * For the `seuclidean` distance you need to supply an additional parameter `V`. `V` should be a **vector** containing the variance of each variable in `X`.\n",
    "\n",
    "  * Choose a suitable number of neighbors. \n",
    "  \n",
    "* Predict the class of the test data using the trained model.\n",
    "\n",
    "* Make a scatterplot of the train and test data with the classification of the test data obtained with the best k-value and distance measures you found -- just one plot per data set is fine. You can use the `classification_plot` function from the toolbox. \n",
    "  * Use the obtained prediction of the test data in your plot.\n",
    "  * Try to study the plot (use all 5 arguments) to see how test data is classified using the train data.\n",
    "\n",
    "* Create the confusion matrix, plot it using the `plot_confusion_matrix` function given below, and calculate the accuracy and error rate. Print or show the accuracy and error rate for each dataset.\n",
    "\n",
    "\n",
    "**Answer the following questions for each dataset:**\n",
    "\n",
    "\n",
    "        \n",
    "* Which distance measures worked best for each of the four problems? Can you explain why?\n",
    "\n",
    "        \n",
    "* How many neighbors were needed for the four problems? Why is a large/small number of neighbors appropriate here? Consider e.g. when clusters are well separated versus when they are overlapping.\n",
    "\n",
    "Hints:\n",
    "\n",
    "* To generate a confusion matrix, you can use the function confusion_matrix() from the module sklearn.metrics. You can use the function below to plot the confusion matrix. Don't remember how to read a confusion matrix? Check the wiki page: https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cedae35cd068fa593fe2e56341aa9a48",
     "grade": false,
     "grade_id": "cell-881a8d7329bd61d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm,y):\n",
    "    df_cm = pd.DataFrame(cm, index = [i+1 for i in np.unique(y)],\n",
    "                  columns = [i+1 for i in np.unique(y)])\n",
    "    plt.figure()\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.ylabel('Actual class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26f2ff9aaa7e1840deeb38980d13ff47",
     "grade": true,
     "grade_id": "cell-c914718fc664cbf0",
     "locked": false,
     "points": 100,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##Answer to question 6.1.1\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f119a5a62deb0a9bf9d45636a42bcb7",
     "grade": true,
     "grade_id": "cell-c365d26e6855010f",
     "locked": false,
     "points": 100,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee25c6a948d2ceb0eeb2631b44e263c6",
     "grade": false,
     "grade_id": "cell-8ecc7df13886d8fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 6.1.2 (1.25 points)\n",
    "In general we can use cross-validation to select the best parameters for our method.This can however be computationally expensive. \n",
    "\n",
    "We now return to the Iris data that we have considered in previous exercises, and will attempt to classify the Iris flowers using KNN. \n",
    "\n",
    "* Load the Iris data into Python with the `pandas` function `read_excel()` and save it to a variable called `iris_data`. Inspect the data by printing the `head()` of the dataframe. \n",
    "\n",
    "* Use the values of the 4 variables `Sepal Length,  Sepal Width,  Petal Length,  Petal Width` to create a data set `X`. Use the `Type` column to create the labels `labels`. `X` should be a numpy array! You can use the `to_numpy()` method for this. `labels` will be a Pandas series.\n",
    "\n",
    "* Convert the Pandas series `labels` to an integer encoding by using the `LabelEncoder` in scikit-learn. Save the integer encoding, which should be a numpy array to a variable called `y`.\n",
    "\n",
    "* Use leave-one-out cross-validation to estimate the optimal number of neighbors, k, for the k-nearest neighbor classifier. Save the vector of averaged errors to a variable called `mean_errors`. This should be a numpy array.\n",
    "\n",
    "* Plot the cross-validation average classification error as a function of k for $k = 1,..,40$.\n",
    "\n",
    "You can use the function `LeaveOneOut` from `sklearn.model_selection`: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html\n",
    "\n",
    "What is the optimal number of neighbors to use for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bce13c66bbd7e3011f794f5ec64f5b4",
     "grade": false,
     "grade_id": "cell-d4a09338afe0c7e2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##Answer to question 6.1.2\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99bc4874acec02527a2cc4b8100b7848",
     "grade": true,
     "grade_id": "cell-5228b8b55ea59d61",
     "locked": true,
     "points": 100,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Checks whether 6.1.2 output is correct\"\"\"\n",
    "\"\"\"DO NOT MODIFY THIS CELL\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50a9bf11b4aef02a9e0d400dee27e050",
     "grade": true,
     "grade_id": "cell-28bebc3e081a2ae6",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a6cc9239636e2bcb8061616a87257d0",
     "grade": false,
     "grade_id": "cell-d5c684910893698d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 6.2 Artificial Neural Networks\n",
    "\n",
    "In this part of the exercise we will use neural networks to classify the xor data. We will consider a network with an input layer, one layer of hidden units and an output layer. The class `sklearn.neural_network.MLPClassifier` can be used to create a Multilayer Perceptron that can minimizes the Cross-Entropy loss function for any dataset X with corresponding labels y. See https://scikit-learn.org/stable/modules/neural_networks_supervised.html \n",
    "\n",
    "We use the data contained in `xor.mat` in the Data folder. \n",
    "\n",
    "#### 6.2.1 (0.5 points)\n",
    "Check out the documentation for `MLPClassifier` and read the documentation well. Make sure you understand at least in general terms how the learning process works. Answer the following questions before you continue:\n",
    "\n",
    "1. For a single layer perceptron, the activation function can be linear, e.g. $f(x) = x$. However, the activation function used in the MLP class is a non-linear function. Why does it not make sense for a MLP to use such a linear activation function? Hint: what does the following computation simplify to if $f(x)$ is such a simple linear function: $f(Wo*f(Wh*X_i))$?\n",
    "2. The MLPClassifier has a few optional parameters. For each of the following parameters, explain how changing the parameter might affect the learning process or the resulting solution:\n",
    "\n",
    "> `hidden_layer_sizes`:\n",
    "\n",
    "> `max_iter`:\n",
    "\n",
    "> `learning_rate`:\n",
    "\n",
    "> `learning_rate_init`:\n",
    "\n",
    "3. Use the following commands to create a small data set\n",
    "\n",
    "> `X = np.array([[0,0],[0,1],[1,0],[1,1]]).`\n",
    "\n",
    "> `y = np.array([0,0,0,1])`\n",
    "     \n",
    "\n",
    "Then: \n",
    "- Create a MLPClassifier with 1 hidden layer containing 1 unit using the `lbfgs`solver and fit the data. You can leave the other parameters unchanged. Use the `score` method of the classifier object to compute the mean accuracy. How well does the MLP perform on this problem? Use the function `plot_boundaries` function from the toolbox to plot the data and the decision boundaries. Why does(n't) it work well with one hidden unit? Could you improve by using more?\n",
    "\n",
    "#### NB: the weights are initialised randomly, so you should run the code a few times untill you get a decent result.\n",
    "\n",
    "**Helpful hint:**\n",
    "- You can plot decision boundaries as follows:\n",
    "\n",
    "`plot_boundaries(X,y,clf)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d2db60b6ac94b26be0ce4f22c3792ef",
     "grade": true,
     "grade_id": "cell-9d41b67efb609fc1",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73bfe7e2649db80247ed098f87b38a1e",
     "grade": true,
     "grade_id": "cell-735ec50c840768e5",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##Answer to question 6.2.1\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db187712b7ee2e38233a89786d8d2f56",
     "grade": false,
     "grade_id": "cell-c65eb2c09f090f0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 6.2.2 loading and visualizing the Xor data (0.5)\n",
    "In this exercise, we'll look at the Xor data in `xor.mat`. Name the extracted variables `X` and `y`.\n",
    "\n",
    "\n",
    "- Load the data into Python using `scipio.io.loadmat(...)` and make `y` a 1d vector. Make a scatter plot of the two attributes in `X`, coloring the points according to the class labels `y` and add a legend. Use matplotlib functions, and no toolbox functions for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "726ccc0e9c3bd157fbc642f853a19dad",
     "grade": true,
     "grade_id": "cell-29ae1f3886162c7e",
     "locked": false,
     "points": 50,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##Answer to question 6.2.2\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e69b42d6ee8a293a44e0a254ea4095ac",
     "grade": false,
     "grade_id": "cell-651d2f68691aeb95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 6.2.3 Optimizing the number of hidden units (3 points) \n",
    "In this exercise, we'll start optimizing a MLPClassifier for use on the Xor data. We've toyed around a bit with finding the optimal number of hidden units, but now we'll optimize them in earnest.\n",
    "\n",
    "- Create a CV loop for MLPClassifier with 1 to 20 hidden units. Fit X and y. Use 10-fold cross-validation `KFold` from `sklearn.model_selection` to create training and test sets and estimate the classification error for both. **In each fold, for each numberof hidden units, run the learning process 5 times and take the average classification error.**  \n",
    "- Determine the optimal number of hidden units.\n",
    "- Plot the decision boundaries of one network with the optimal number of hidden units trained on the entire data set, and explain why the network performs so well/poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b57960909eb8da56a2d80344b1570c9",
     "grade": true,
     "grade_id": "cell-43a21e78b44b6141",
     "locked": false,
     "points": 250,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##Answer to question 6.2.3\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec4e9ba786b4d7af64e24f6158c4ad16",
     "grade": true,
     "grade_id": "cell-adb15a9e87187331",
     "locked": false,
     "points": 50,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27cfad07a10a272fc8a009aa2ebd1b86",
     "grade": false,
     "grade_id": "cell-e96de244ac8aeee8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 6.3 Support Vector Machines\n",
    "\n",
    "In this subsection we're taking a look at Support Vector Machines.\n",
    "We'll again analyze the Xor data. and look at what some of the hyperparameters do.\n",
    "\n",
    "### 6.3.1 Linear kernels (1 point)\n",
    "- First, use a linear kernel support vector machine from Scikit-learn, `SVC`, and train it on the Xor data. \n",
    "- Again, plot the boundaries of the classification using the `plot_boundaries` function from the toolbox\n",
    "- What do you observe when you use the basic settings, but with a linear kernel? Why does or doesn't the model perform well? \n",
    "- Do you get different results when rerunning the algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce21ace93dd0a8b99404ad22976840a5",
     "grade": true,
     "grade_id": "cell-db326907accda924",
     "locked": false,
     "points": 50,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a650edbdd5c5effc776270b529e0f0f",
     "grade": true,
     "grade_id": "cell-27dfca3ea13a3b24",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e3345dd82235f0c7ad613a103760df8",
     "grade": false,
     "grade_id": "cell-e4157c8d905eeb8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 6.3.2 The kernel trick (1.25 points)\n",
    "In order to solve the problem a linear kernel SVM has when facing such multimodal data, we can transform the data using a so called kernel. Several kernels exist, but in this case we'll look into a second degree polynomial kernel first.\n",
    "\n",
    "There are several ways to construct a second degree polynomial kernel\n",
    "- You can include or exclude the bias (the ^0 term)\n",
    "- You can include or exclude non-interactions (X_1^d) terms\n",
    "\n",
    "In this case, we can just add a third variable/feature to the data, namely the interaction term $x_1 * x_2$. **So we don't include the bias or the $x_1^2$ and $x_2^2$ terms.**\n",
    "\n",
    "- Calculate the third interaction feature for the kernel. You can do this manually, or using the `PolynomialFeatures` function from Scikit-learn with the correct settings. Verify you end up with a $400*3$ matrix. Assign this NumPy array to a variable called `KX`.\n",
    "- Make a 3D scatterplot of the transformed data, color the points by the label and add a legend\n",
    "- Use a linear kernel SVM with otherwise default settings to predict `y`. What is the accuracy of the classifier now? Save the accuracy to a variable called `second_degree_svm_accuracy`. Does this match up with what you see in the plot? Can you find a separating hyperplane?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58fa3d34a6e49ed57e9e193af7804cca",
     "grade": false,
     "grade_id": "cell-46b977b06d43a181",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e39579e2161b5cc5d0398c59965f0872",
     "grade": true,
     "grade_id": "cell-ef08773205385f43",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e1e2cd4c566ec8d570ce58921ad44f4",
     "grade": true,
     "grade_id": "cell-947e92d40bd70c2e",
     "locked": true,
     "points": 100,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Checks whether 6.3.2 output is correct\"\"\"\n",
    "\"\"\"DO NOT MODIFY THIS CELL\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc94f586f710d1b9b25e0aae3238aac1",
     "grade": false,
     "grade_id": "cell-bdfbc58160e0ae4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 6.3.3 Using the kernel trick directly (0.75 points)\n",
    "\n",
    "Instead of manually applying the kernel trick, we can also use the polynomial kernel directly when initializing the SVC object. \n",
    "\n",
    "- Apply SVM using a second degree polynomial kernel and calculate and print the score. Save the score to a variable called `second_degree_svm_accuracy2`.\n",
    "- Use the `plot_boundaries` function to show the classification boundaries. \n",
    "- Is the result the same as when you applied the trick manually? Why (not)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09a1760754e5ad75b0cbc28ec10302ff",
     "grade": true,
     "grade_id": "cell-5610b69451dc2c45",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d82556b7e8a181c99f91e0d033e605d4",
     "grade": true,
     "grade_id": "cell-67b6991153e5b137",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a99841825add195cce012e42e7d42139",
     "grade": true,
     "grade_id": "cell-62f2c962d7cc6339",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Checks whether 6.3.3 output is correct\"\"\"\n",
    "\"\"\"DO NOT MODIFY THIS CELL\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
